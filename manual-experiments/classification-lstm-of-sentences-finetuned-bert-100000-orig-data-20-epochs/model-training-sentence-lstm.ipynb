{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from segtok import tokenizer\n",
    "from utils import *\n",
    "import hickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Hyperparameters\n",
    "enable_orig = True\n",
    "enable_aug = False\n",
    "enable_aug3 = False\n",
    "max_training_samples = 100000\n",
    "max_tokenized_length = 64\n",
    "num_sentences = 10\n",
    "\n",
    "batch_size = 128\n",
    "batch_size_finetuning = 32\n",
    "epochs = 20\n",
    "epochs_finetuning = 1\n",
    "\n",
    "lstm_hidden_size = 1024\n",
    "\n",
    "experiment_id = f\"classification-lstm-{lstm_hidden_size}-of-sentences-finetuned-bert-{max_training_samples}-orig-data-{epochs}-epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "experiment_dir = f\"completed-experiments/{experiment_id}\"\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_parsing import load_dataset, load_gen_dataset\n",
    "data = load_dataset(\"./yelp_review_training_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import split_train_validation\n",
    "def get_train_valid():\n",
    "    train_x, valid_x, train_y, valid_y = split_train_validation(data, 0.01)\n",
    "\n",
    "    if not enable_orig:\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "\n",
    "    if enable_aug:\n",
    "        aug_data = load_gen_dataset(\"./new_data.json\") + load_gen_dataset(\"./new_data2.json\")\n",
    "        train_x += [i[0] for i in aug_data]\n",
    "        train_y += [i[1] for i in aug_data]\n",
    "\n",
    "    if enable_aug3:\n",
    "        aug_data3 = load_gen_dataset(\"./new_data3.json\")\n",
    "        train_x += [i[0] for i in aug_data3]\n",
    "        train_y += [i[1] for i in aug_data3]\n",
    "    \n",
    "    return [x.encode(\"utf-8\") for x in train_x], [x.encode(\"utf-8\") for x in valid_x], train_y, valid_y\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = memo_load(\n",
    "    get_train_valid,\n",
    "    f\"{experiment_dir}/split_data\"\n",
    ")\n",
    "\n",
    "train_x = [x.decode(\"utf-8\") for x in train_x]\n",
    "valid_x = [x.decode(\"utf-8\") for x in valid_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(valid_x))\n",
    "print(len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the BERT\n",
    "import numpy as np\n",
    "\n",
    "def get_finetuning_data():\n",
    "    train_x_numerized = []\n",
    "    train_x_mask = []\n",
    "    train_y_per_sentence = []\n",
    "    for i, text in tqdm(list(enumerate(train_x[:max_training_samples]))):\n",
    "        doc = nlp(text)\n",
    "        sents = [str(sent) for sent in doc.sents]\n",
    "        for sentence in sents[:num_sentences]:\n",
    "            tokenized = tokenizer(sentence, truncation=True, padding=\"max_length\", max_length=max_tokenized_length)[0]\n",
    "            train_x_numerized.append(tokenized.ids)\n",
    "            train_x_mask.append(tokenized.attention_mask)\n",
    "            train_y_per_sentence.append(train_y[i])\n",
    "\n",
    "    valid_x_numerized = []\n",
    "    valid_x_mask = []\n",
    "    valid_y_per_sentence = []\n",
    "    for i, text in tqdm(list(enumerate(valid_x))):\n",
    "        doc = nlp(text)\n",
    "        sents = [str(sent) for sent in doc.sents]\n",
    "        for sentence in sents[:num_sentences]:\n",
    "            tokenized = tokenizer(sentence, truncation=True, padding=\"max_length\", max_length=max_tokenized_length)[0]\n",
    "            valid_x_numerized.append(tokenized.ids)\n",
    "            valid_x_mask.append(tokenized.attention_mask)\n",
    "            valid_y_per_sentence.append(valid_y[i])\n",
    "\n",
    "    train_x_numerized = np.array(train_x_numerized)\n",
    "    train_x_mask = np.array(train_x_mask)\n",
    "    train_y_per_sentence = np.array(train_y_per_sentence)\n",
    "    valid_x_numerized = np.array(valid_x_numerized)\n",
    "    valid_x_mask = np.array(valid_x_mask)\n",
    "    valid_y_per_sentence = np.array(valid_y_per_sentence)\n",
    "    return train_x_numerized, train_x_mask, train_y_per_sentence, valid_x_numerized, valid_x_mask, valid_y_per_sentence\n",
    "\n",
    "from utils import memo_load\n",
    "(train_x_numerized, train_x_mask, train_y_per_sentence, valid_x_numerized, valid_x_mask, valid_y_per_sentence) = memo_load(\n",
    "    lambda: get_finetuning_data(),\n",
    "    f\"{experiment_dir}/training_data_finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ReviewPredictionModel\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_finetuning():\n",
    "    embedding_bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)\n",
    "\n",
    "    model_to_train_finetuning = ReviewPredictionModel(0, max_tokenized_length)\n",
    "    model_to_train_finetuning.transformer = embedding_bert\n",
    "    model_to_train_finetuning.to(device)\n",
    "    optimizer = optim.Adam(model_to_train_finetuning.parameters(), lr=1e-5)\n",
    "    \n",
    "    training_accuracies_finetuning, validation_accuracies_finetuning = run_training_loop(\n",
    "        model_to_train_finetuning, optimizer, device,\n",
    "        batch_size_finetuning, epochs_finetuning,\n",
    "        train_x_numerized, train_x_mask, train_y_per_sentence, valid_x_numerized, valid_x_mask, valid_y_per_sentence,\n",
    "        max_validation_examples=256,\n",
    "        model_id=experiment_id, tag=\"finetuning\"\n",
    "    )\n",
    "    \n",
    "    return embedding_bert, training_accuracies_finetuning, validation_accuracies_finetuning\n",
    "\n",
    "def store_finetuning(tup, folder):\n",
    "    embedding_bert, training_accuracies_finetuning, validation_accuracies_finetuning = tup\n",
    "    th.save(embedding_bert.state_dict(), f\"{folder}/model.pt\")\n",
    "    hickle.dump((training_accuracies_finetuning, validation_accuracies_finetuning), f\"{folder}/accuracies.hkl\", mode=\"w\")\n",
    "\n",
    "def load_finetuning(folder):\n",
    "    embedding_bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)\n",
    "    embedding_bert.load_state_dict(th.load(f\"{folder}/model.pt\"))\n",
    "    embedding_bert.eval()\n",
    "    embedding_bert.to(device)\n",
    "    training_accuracies_finetuning, validation_accuracies_finetuning = hickle.load(f\"{folder}/accuracies.hkl\")\n",
    "    return embedding_bert, training_accuracies_finetuning, validation_accuracies_finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import run_training_loop\n",
    "\n",
    "from utils import memo_load\n",
    "embedding_bert, training_accuracies_finetuning, validation_accuracies_finetuning = manual_memo(\n",
    "    train_finetuning, store_finetuning, load_finetuning,\n",
    "    f\"{experiment_dir}/finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(training_accuracies_finetuning)), training_accuracies_finetuning, label = \"Training Accuracy\")\n",
    "plt.plot(list(map(lambda x: x * 100, range(len(validation_accuracies_finetuning)))), validation_accuracies_finetuning, label = \"Validation Accuracy\")\n",
    "plt.xlabel(\"Training Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{experiment_dir}/training-plot-finetuning.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "embedding_bert.to(device)\n",
    "\n",
    "def get_embeds(x_data):\n",
    "    concatted_shape = None\n",
    "    pad_value = None\n",
    "    embeds = []\n",
    "    for text in tqdm(x_data):\n",
    "        doc = nlp(text)\n",
    "        embeddeds = []\n",
    "        sents = list(doc.sents)\n",
    "        all_tokenized = []\n",
    "        for sentence in sents[:num_sentences]:\n",
    "            sentence = str(sentence)\n",
    "            tokenized = tokenizer(sentence, truncation=True, padding=\"max_length\", max_length=max_tokenized_length)[0]\n",
    "            all_tokenized.append(tokenized.ids)\n",
    "        \n",
    "        with th.no_grad():\n",
    "            sentence_tensor = th.tensor(all_tokenized).to(device)\n",
    "            concatted = np.concatenate([\n",
    "                # take output corresponding to CLS\n",
    "                embedding_bert.bert(sentence_tensor, output_hidden_states=True, return_dict=True)[1].cpu().numpy(),\n",
    "                np.zeros((len(all_tokenized), 1))\n",
    "            ], axis=1)\n",
    "            \n",
    "            if not concatted_shape:\n",
    "                concatted_shape = concatted.shape\n",
    "                pad_value = np.zeros(concatted_shape[1])\n",
    "                pad_value[-1] = 1\n",
    "            \n",
    "            embeddeds += list(concatted)\n",
    "\n",
    "        if len(sents) < num_sentences:\n",
    "            embeddeds += [pad_value] * (num_sentences - len(sents))\n",
    "\n",
    "        embeds.append(embeddeds)\n",
    "    return np.array(embeds)\n",
    "\n",
    "from utils import memo_load\n",
    "train_x_embeds = memo_load(lambda: get_embeds(train_x[:max_training_samples]), f\"{experiment_dir}/training_data\")\n",
    "valid_x_embeds = memo_load(lambda: get_embeds(valid_x), f\"{experiment_dir}/valid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_sentence_lstm import ReviewPredictionModel\n",
    "import torch as th\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_main():\n",
    "    print(train_x_embeds.shape)\n",
    "    model_to_train = ReviewPredictionModel(train_x_embeds.shape[2], lstm_hidden_size)\n",
    "    model_to_train.to(device)\n",
    "    optimizer = optim.Adam(model_to_train.parameters(), lr=1e-5)\n",
    "    \n",
    "    training_accuracies, validation_accuracies = run_training_loop(\n",
    "        model_to_train, optimizer, device,\n",
    "        batch_size, epochs,\n",
    "        train_x_embeds, None, np.array(train_y), valid_x_embeds, None, np.array(valid_y),\n",
    "        model_id=experiment_id\n",
    "    )\n",
    "    \n",
    "    return model_to_train, training_accuracies, validation_accuracies\n",
    "\n",
    "def store_main(tup, folder):\n",
    "    model_to_train, training_accuracies, validation_accuracies = tup\n",
    "    th.save(model_to_train.state_dict(), f\"{folder}/model.pt\")\n",
    "    hickle.dump((training_accuracies, validation_accuracies), f\"{folder}/accuracies.hkl\", mode=\"w\")\n",
    "\n",
    "def load_main(folder):\n",
    "    model_to_train = ReviewPredictionModel(train_x_embeds.shape[2], train_x_embeds.shape[2])\n",
    "    model_to_train.load_state_dict(th.load(f\"{folder}/model.pt\"))\n",
    "    model_to_train.eval()\n",
    "    model_to_train.to(device)\n",
    "    training_accuracies, validation_accuracies = hickle.load(f\"{folder}/accuracies.hkl\")\n",
    "    return model_to_train, training_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import run_training_loop\n",
    "\n",
    "from utils import memo_load\n",
    "main_model, training_accuracies, validation_accuracies = manual_memo(\n",
    "    train_main, store_main, load_main,\n",
    "    f\"{experiment_dir}/main\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(training_accuracies)), training_accuracies, label = \"Training Accuracy\")\n",
    "plt.plot(list(map(lambda x: x * 100, range(len(validation_accuracies)))), validation_accuracies, label = \"Validation Accuracy\")\n",
    "plt.xlabel(\"Training Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{experiment_dir}/training-plot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "model-training-sentence-lstm.ipynb",
   "output_path": "model-training-sentence-lstm.ipynb",
   "parameters": {},
   "start_time": "2021-05-05T05:47:48.702322",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
